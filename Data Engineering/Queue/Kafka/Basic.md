# Kafka
카프카(Kafka)는 분산 메시징 시스템(distributed messaging system)으로, LinkedIn에서 개발한 오픈소스 프로젝트입니다. 대용량의 데이터를 실시간으로 처리하는데 특화되어 있으며, 데이터를 안정적으로 전달하고, 메시지 유실 가능성을 최소화하는 기능을 제공합니다.

카프카는 다수의 프로듀서(producer)에서 생성된 메시지 데이터를 여러 개의 브로커(broker)에 분산 저장하고, 이를 다시 다수의 컨슈머(consumer)에게 분배하여 데이터를 처리합니다. 이를 통해 대량의 데이터를 고속으로 처리하고, 여러 시스템 간의 데이터 전송을 단순하게 할 수 있습니다.

카프카는 일반적으로 실시간 스트리밍 데이터 처리, 이벤트 기반 아키텍처(event-driven architecture), 로그 수집 및 분석(log collection and analysis), 메시지 큐(message queue), 메시지 브로커(message broker) 등의 용도로 사용됩니다.
<br>

## Topic
카프카(Kafka) 토픽은 카프카에서 메시지가 발행되는 주제를 말합니다. 카프카에서는 토픽이라는 개념을 사용하여 메시지를 구분합니다. 메시지를 발행(produce)할 때는 해당 메시지를 어떤 토픽에 발행할 것인지를 지정하며, 메시지를 구독(consume)할 때도 어떤 토픽에서 메시지를 구독할 것인지를 지정합니다.

각 토픽은 일련의 파티션(partition)으로 구성됩니다. 파티션은 논리적인 메시지 스트림을 나타내며, 하나의 파티션은 여러 개의 메시지를 포함할 수 있습니다. 파티션은 독립적으로 작동하며, 각각의 파티션은 순서가 보장되는 메시지 시퀀스를 형성합니다. 카프카는 파티션을 통해 메시지의 병렬 처리를 가능하게 하며, 이는 매우 큰 규모의 데이터 처리에 매우 유용합니다.

또한, 각 토픽은 설정된 replication factor만큼의 복제본(replica)을 가질 수 있습니다. 이는 카프카에서 고가용성(High Availability)을 보장하는 방법 중 하나입니다. replication factor는 토픽 생성 시 설정하며, 각각의 복제본은 다른 브로커에서 실행됩니다. 만약 복제본 중 하나가 실패하더라도 다른 복제본이 대신 처리할 수 있습니다.

각 토픽은 설정된 retention period 만큼의 시간동안 메시지를 보존할 수 있습니다. 이는 카프카에서 메시지를 보존하고 검색할 수 있는 시간을 결정하는 중요한 요소입니다. 또한, 카프카는 토픽의 크기나 성능에 따라 파티션 수를 조정할 수 있습니다.

카프카에서는 대량의 실시간 스트림 데이터를 처리하기 위해 설계되어 있으며, 여러 애플리케이션에서 공유되는 데이터를 신속하게 처리할 수 있습니다. 토픽은 이러한 스트림 데이터의 발행과 구독을 가능하게 하며, 각각의 메시지는 레코드(record) 단위로 저장됩니다. 이는 데이터 파이프라인에서 고속, 대용량 데이터 처리를 위해 매우 유용한 기능입니다.
<br>

## Partition, Segment
카프카는 대용량의 데이터를 분산 저장하고 처리할 수 있는 분산 데이터 처리 플랫폼입니다. 이를 위해 카프카는 데이터를 분할하여 여러 개의 파티션에 저장하고, 각 파티션은 여러 개의 세그먼트로 구성됩니다.

파티션 (Partition)
파티션은 데이터를 분산하여 저장하기 위한 논리적인 단위입니다. 카프카에서는 하나의 토픽이 여러 개의 파티션으로 구성될 수 있습니다. 각 파티션은 다른 파티션과 독립적으로 데이터를 저장하고, 순서대로 읽을 수 있습니다. 이를 통해 카프카는 수천 대의 브로커에서 수백만 건의 메시지를 초당 처리할 수 있습니다.

세그먼트 (Segment)
세그먼트는 각 파티션을 더 작은 단위로 분할하여 데이터를 저장하기 위한 물리적인 단위입니다. 각 파티션은 일정 크기로 분할된 여러 개의 세그먼트로 구성됩니다. 세그먼트의 크기는 설정에 따라 달라질 수 있지만, 보통 1GB 또는 1주일로 설정됩니다. 세그먼트는 파일 시스템에 저장되며, 이를 통해 디스크의 I/O 성능을 최적화할 수 있습니다. 또한, 카프카는 세그먼트 단위로 데이터를 압축하여 저장함으로써 저장 공간을 절약할 수 있습니다.

각 세그먼트는 순차적인 메시지 집합을 저장하며, 새로운 메시지가 추가될 때마다 새로운 세그먼트가 생성됩니다. 이를 통해 카프카는 매우 큰 양의 데이터를 저장할 수 있으며, 기존 세그먼트를 삭제하거나 수정하는 것이 불가능하므로 데이터 무결성과 보관 기간을 보장할 수 있습니다.
<br>

## Broker, Zookeeper
카프카 브로커는 카프카에서 메시지를 수신, 저장, 전송하는 서버입니다. 각각의 브로커는 별도의 프로세스로 실행되며, 카프카 클러스터 내에서 분산되어 작동합니다. 브로커는 주어진 토픽에 대한 모든 메시지의 전송과 저장을 관리하고, 프로듀서와 컨슈머가 브로커에 메시지를 보내고 받을 수 있도록 합니다.

주키퍼는 분산 애플리케이션을 위한 중앙 집중식 서비스로, 분산 시스템에서 데이터와 구성 정보를 저장하고 처리합니다. 카프카에서는 주키퍼를 사용하여 브로커의 구성 정보와 토픽 파티션 정보 등을 관리합니다. 또한, 주키퍼는 브로커의 리더 선출, 컨트롤러 선택 및 브로커의 동기화 등 클러스터 전체적인 관리 역할을 수행합니다.

카프카 브로커와 주키퍼는 함께 동작하여, 카프카 클러스터 내에서 메시지 전송, 저장, 관리, 복제, 토픽 파티션 할당 등을 수행합니다.
<br>

## Producer
카프카 프로듀서는 카프카 메시징 시스템에서 메시지를 생성하고 발행하는 역할을 수행하는 클라이언트 애플리케이션입니다. 프로듀서는 카프카 클러스터의 특정 토픽으로 데이터를 전송하고, 여러 개의 파티션으로 데이터를 분할하여 각 파티션에 메시지를 기록합니다.

프로듀서는 일반적으로 다음과 같은 일련의 과정을 거쳐 메시지를 생성하고 발행합니다.

메시지 생성: 프로듀서는 사용자나 애플리케이션에서 생성한 메시지를 카프카 메시징 시스템에 발행하기 전에 먼저 생성합니다.

메시지 분할: 카프카에서는 메시지를 여러 개의 파티션으로 분할하여 저장합니다. 이를 통해 대량의 메시지를 분산처리할 수 있으며, 각 파티션에 대해 병렬적으로 메시지를 처리할 수 있습니다.

메시지 발행: 프로듀서는 메시지를 생성하고 분할한 뒤, 카프카 클러스터에 있는 해당 토픽의 파티션에 메시지를 발행합니다. 이 때, 메시지 발행에 대한 응답을 받는 것은 선택적입니다.

에러 처리: 프로듀서는 메시지 발행 시 에러가 발생할 수 있습니다. 이 때, 에러를 처리하기 위해 재시도, 메시지 저장 등의 방법을 사용할 수 있습니다.

카프카 프로듀서는 대규모의 데이터를 처리하며, 실시간 데이터 파이프라인에서 중요한 역할을 담당합니다. 데이터 소스로부터 메시지를 생성하고, 빠르고 안정적인 메시지 발행을 위해 사용됩니다.
<br>

## Consumer
카프카 컨슈머는 카프카에서 메시지를 소비하는 역할을 합니다. 컨슈머는 카프카에서 토픽(topic)에 대해 등록되어 있으며, 해당 토픽에서 메시지를 가져와 처리합니다.

카프카 컨슈머는 다음과 같은 특징을 가집니다.

컨슈머 그룹(consumer group)으로 묶일 수 있습니다. 같은 컨슈머 그룹에 속한 컨슈머들은 같은 토픽에서 메시지를 분산 소비합니다.
컨슈머는 카프카에서 메시지를 가져올 때 오프셋(offset)을 사용합니다. 오프셋은 해당 토픽 내에서 메시지의 위치를 나타내며, 각각의 컨슈머는 자신이 읽은 마지막 오프셋을 기억합니다. 따라서 컨슈머가 종료되고 다시 실행될 때는 마지막으로 읽은 오프셋부터 메시지를 가져오게 됩니다.
컨슈머는 카프카에서 메시지를 가져오는 시점에 따라 두 가지 방식으로 분류됩니다. 첫 번째는 pull 방식으로, 컨슈머가 직접 카프카에게 메시지를 요청하여 가져옵니다. 두 번째는 push 방식으로, 카프카가 메시지를 컨슈머에게 보내는 방식입니다. 이 경우 컨슈머는 미리 카프카에게 요청해둔 구독(subscription) 정보를 바탕으로 메시지를 받게 됩니다.
카프카 컨슈머는 실시간 데이터 파이프라인, 로그 처리 등 다양한 분야에서 사용됩니다. 예를 들어, 웹 로그 데이터를 실시간으로 분석하기 위해 카프카에서 로그 데이터를 수집하고, 컨슈머를 이용해 해당 데이터를 처리하고 분석할 수 있습니다.
<br>

## Replication
카프카 레플리케이션은 데이터의 고가용성과 신뢰성을 보장하기 위한 메커니즘입니다. 레플리케이션은 데이터를 여러 개의 브로커에 복제하여, 하나의 브로커에 장애가 발생하더라도 다른 브로커에서 데이터를 읽을 수 있도록 합니다.

카프카 레플리케이션은 여러 개의 브로커가 클러스터를 구성하고 있을 때, 특정 토픽의 파티션에 대해 복제본을 만들어 다른 브로커에 저장하는 것을 말합니다. 이렇게 복제된 데이터는 리더 복제본과 팔로워 복제본으로 나뉘어져 있습니다.

리더 복제본은 해당 파티션에 대한 쓰기 요청을 처리하고, 복제본들 사이에서 데이터를 동기화하여 데이터 일관성을 보장합니다. 팔로워 복제본은 리더 복제본으로부터 데이터를 복제받아 동기화된 데이터를 갖게 됩니다. 만약 리더 복제본이 실패하면, 카프카는 자동으로 팔로워 복제본 중에서 새로운 리더 복제본을 선정하여 데이터 일관성을 유지합니다.

카프카 레플리케이션은 다음과 같은 특징을 갖습니다.

높은 신뢰성: 복제본을 통해 데이터의 고가용성과 신뢰성을 보장합니다.
높은 확장성: 브로커를 추가하면 쉽게 스케일 아웃이 가능합니다.
성능: 레플리케이션은 비동기적으로 동작하므로, 복제작업이 프로듀서와 컨슈머의 처리속도에 영향을 주지 않습니다.
데이터 일관성: 복제본은 리더 복제본으로부터 동기화되므로 데이터 일관성을 보장합니다.
<br>

## In-Sync Replicas
카프카에서 인싱크 레플리카(in-sync replica)란, ISR이라고도 부르며, 리더 브로커와 동기화된 브로커들을 말합니다. ISR에 속한 브로커들은 모두 동일한 메시지를 유지하고 있기 때문에, 리더 브로커에서 메시지를 처리할 수 없는 경우, ISR 내에서 새로운 리더를 선출하여 처리합니다.

카프카에서는 일반적으로 각 파티션에 대해 여러 개의 레플리카를 유지합니다. 이는 고가용성을 보장하기 위한 것으로, 각 레플리카는 서로 다른 브로커에서 실행됩니다. 이 중에서 ISR에 속한 레플리카들은 리더 브로커와 동기화되어 있기 때문에, 메시지 유실을 최소화할 수 있습니다.

인싱크 레플리카에 대한 개수는 replication.factor 설정에 의해 결정됩니다. 이 값은 각 파티션에 대해 유지되는 레플리카의 개수를 나타내며, 일반적으로 2 또는 3으로 설정됩니다. 레플리카 개수가 많을수록 고가용성은 높아지지만, 데이터 복제 및 처리에 필요한 리소스도 증가합니다.
