# Kafka Connect
카프카 커넥트는 Kafka Connect라는 분산 데이터 통합 플랫폼으로 다양한 소스와 대상 시스템 간의 데이터 이동을 지원하는 오픈소스 프로젝트입니다. Kafka Connect는 대부분의 경우 데이터 소스와 대상 시스템 간의 중개 역할을 하면서 이를 위한 일련의 Connector를 제공합니다.

Kafka Connect는 대규모 데이터 이동 및 데이터 통합 작업을 지원하며 대용량의 데이터를 처리할 수 있도록 설계되었습니다. 또한, Kafka Connect는 확장성이 우수하며 쉽게 구성하고 운영할 수 있는 기능을 제공합니다.

Kafka Connect의 구성요소는 크게 Connectors, Tasks, Converters, Worker, REST API로 구성됩니다. Connector는 데이터 소스 및 대상 시스템에 대한 연결을 설정하는 구성요소이며, 여러 개의 Task를 가질 수 있습니다. Task는 Kafka topic의 특정 파티션에 대한 데이터 이동을 수행하는 단위입니다. Converter는 Connector가 데이터를 변환할 때 사용되는 클래스로, 데이터 변환을 위한 로직을 담고 있습니다. Worker는 Kafka Connect에서 Connector와 Task의 실행을 관리하고, 자원 할당, 로그 처리 등의 역할을 수행합니다. REST API는 Kafka Connect 클러스터를 관리하기 위한 API를 제공합니다.

## Kafka Connector
카프카 커넥터는 카프카와 다른 시스템 사이의 데이터 이동을 위해 구성 가능한 플러그인 모듈입니다. 카프카 커넥트 플랫폼에서는 데이터 소스와 데이터 대상을 모두 지원합니다. 커넥터는 데이터를 추출하여 카프카로 보낼 수도 있고 카프카에서 데이터를 가져와 다른 시스템으로 전송할 수도 있습니다.

카프카 커넥터는 이러한 작업을 수행하는데 필요한 다양한 기능과 유틸리티를 제공합니다. 예를 들어 커넥터는 데이터 변환 및 필터링, 데이터 포맷 변환, 스키마 레지스트리 연동 등을 지원합니다.

카프카 커넥터는 카프카와 다른 시스템 간의 데이터 이동을 단순화하며 일반적으로 사용되는 데이터 전송 시나리오를 쉽게 처리할 수 있도록 지원합니다. 또한 커넥터는 스케일 아웃 가능하며 분산 환경에서도 안정적으로 동작합니다.

카프카 커넥터는 다양한 종류의 커넥터를 지원합니다. 예를 들어 데이터베이스 커넥터, 파일 커넥터, 메시징 시스템 커넥터, 클라우드 서비스 커넥터 등이 있습니다. 이러한 커넥터를 사용하면 카프카와 다른 시스템 간의 데이터 이동을 쉽게 구성할 수 있습니다.

커넥터는 JSON 형식으로 작성되어 있으며 이를 통해 쉽게 구성할 수 있습니다. 또한, 커넥터는 REST API를 통해 관리되며 이를 통해 커넥터의 실행, 일시 중지, 재시작 등을 수행할 수 있습니다.

커넥터는 카프카의 높은 처리량, 낮은 지연 시간 및 분산 처리 능력을 활용하여 대규모 데이터 이동을 처리할 수 있습니다. 이를 통해 비즈니스 요구 사항에 따라 더 많은 데이터를 처리하고 빠르게 대응할 수 있습니다.

## MongoDB Sink Connector
MongoDB Sink Connector를 통해 카프카 토픽 데이터를 MongoDB로 전송할 수 있습니다.

우선적으로 아래 링크에 접속하여 MongoDB Sink Connector 설치합니다.

https://www.confluent.io/hub/mongodb/kafka-connect-mongodb
